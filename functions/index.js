/**
 * ğŸ” Cloud Functions cho há»‡ thá»‘ng Nháº­n diá»‡n khuÃ´n máº·t sinh viÃªn
 * MÃ´i trÆ°á»ng: Node.js 22 + Firebase Functions v2
 * âœ… ÄÃ£ táº¯t App Check Ä‘á»ƒ test dá»… dÃ ng
 */

const { onRequest, onCall } = require("firebase-functions/v2/https");
const { onObjectFinalized } = require("firebase-functions/v2/storage");
const { setGlobalOptions } = require("firebase-functions/v2");
const admin = require("firebase-admin");
const axios = require("axios");

// âœ… Khá»Ÿi táº¡o Firebase Admin SDK
admin.initializeApp();

// âœ… Cáº¥u hÃ¬nh máº·c Ä‘á»‹nh cho toÃ n bá»™ Function
setGlobalOptions({
    region: "us-central1",
    maxInstances: 10,
    timeoutSeconds: 60,
    memory: "256MB",
});

// =======================================================
// ğŸ”¹ Xá»­ lÃ½ áº£nh khuÃ´n máº·t sinh viÃªn khi upload lÃªn Storage
// =======================================================
exports.processStudentFace = onObjectFinalized(
    {
        memory: "512MB",
        timeoutSeconds: 120,
    },
    async (event) => {
        const filePath = event.data.name;
        const bucketName = event.data.bucket;

        // Bá» qua náº¿u khÃ´ng pháº£i thÆ° má»¥c student_faces/
        if (!filePath || !filePath.startsWith("student_faces/")) {
            console.log("âš ï¸ KhÃ´ng pháº£i áº£nh khuÃ´n máº·t sinh viÃªn, bá» qua...");
            return null;
        }

        try {
            console.log(`ğŸ”„ Äang xá»­ lÃ½ áº£nh: ${filePath}`);

            // 1ï¸âƒ£ Chuáº©n bá»‹ URL áº£nh cho Google Vision API
            const imageUri = `gs://${bucketName}/${filePath}`;

            // 2ï¸âƒ£ Gá»i Google Vision API Ä‘á»ƒ phÃ¡t hiá»‡n khuÃ´n máº·t
            const faceDetection = await detectFaces(imageUri);

            if (faceDetection.faces.length === 0)
                throw new Error("KhÃ´ng phÃ¡t hiá»‡n khuÃ´n máº·t trong áº£nh!");

            if (faceDetection.faces.length > 1)
                throw new Error("PhÃ¡t hiá»‡n nhiá»u hÆ¡n 1 khuÃ´n máº·t â€” chá»‰ dÃ¹ng áº£nh 1 ngÆ°á»i!");

            const face = faceDetection.faces[0];

            // 3ï¸âƒ£ Táº¡o vector Ä‘áº·c trÆ°ng (embedding)
            const embedding = createEmbeddingFromFace(face);

            // 4ï¸âƒ£ Láº¥y studentId tá»« Ä‘Æ°á»ng dáº«n file
            const studentId = filePath.split("/")[1];
            if (!studentId) throw new Error("KhÃ´ng láº¥y Ä‘Æ°á»£c studentId tá»« Ä‘Æ°á»ng dáº«n!");

            // 5ï¸âƒ£ LÆ°u vÃ o Firestore
            await admin.firestore().collection("students").doc(studentId).set(
                {
                    studentId,
                    faceImageUrl: `https://storage.googleapis.com/${bucketName}/${encodeURIComponent(filePath)}`,
                    faceEmbedding: embedding,
                    faceBounds: face.bounds,
                    confidence: face.detectionConfidence,
                    landmarks: face.landmarks,
                    processedAt: admin.firestore.FieldValue.serverTimestamp(),
                    status: "registered",
                },
                { merge: true }
            );

            console.log(`âœ… ÄÃ£ lÆ°u embedding cho sinh viÃªn: ${studentId}`);

            return { success: true, studentId, embeddingLength: embedding.length };
        } catch (error) {
            console.error("âŒ Lá»—i khi xá»­ lÃ½ áº£nh:", error);

            const studentId = filePath.split("/")[1];
            if (studentId) {
                await admin.firestore().collection("processingErrors").add({
                    studentId,
                    filePath,
                    error: error.message,
                    timestamp: admin.firestore.FieldValue.serverTimestamp(),
                });
            }

            return { success: false, error: error.message };
        }
    }
);

// =======================================================
// ğŸ”¹ So sÃ¡nh hai embedding khuÃ´n máº·t
// =======================================================
exports.compareFaces = onCall(
    {
        memory: "256MB",
        timeoutSeconds: 30,
        enforceAppCheck: false, // âš ï¸ Táº¯t App Check Ä‘á»ƒ test
    },
    async (request) => {
        try {
            const { embedding1, embedding2 } = request.data;
            if (!embedding1 || !embedding2)
                throw new Error("Thiáº¿u dá»¯ liá»‡u embedding Ä‘á»ƒ so sÃ¡nh!");

            const similarity = calculateCosineSimilarity(embedding1, embedding2);

            return {
                success: true,
                similarity,
                isMatch: similarity > 0.6,
                matchPercentage: (similarity * 100).toFixed(1),
            };
        } catch (error) {
            console.error("âŒ Lá»—i khi so sÃ¡nh khuÃ´n máº·t:", error);
            // Quan trá»ng: Pháº£i nÃ©m ra lá»—i Ä‘á»ƒ client Flutter báº¯t Ä‘Æ°á»£c mÃ£ lá»—i
            throw new Error(error.message); 
        }
    }
);

// =======================================================
// ğŸ”¹ TrÃ­ch xuáº¥t embedding tá»« URL áº£nh (Vision API)
// =======================================================
exports.extractFaceEmbedding = onCall(
    {
        memory: "512MB",
        timeoutSeconds: 60,
        enforceAppCheck: false, // âš ï¸ Táº¯t App Check Ä‘á»ƒ test
    },
    async (request) => {
        // Thay vÃ¬ imageUrl, chÃºng ta nháº­n bucket vÃ  path tá»« client
        const { bucketName, filePath } = request.data;
        
        // Kiá»ƒm tra Ä‘áº§u vÃ o má»›i
        if (!bucketName || !filePath) {
            throw new Error("Thiáº¿u bucketName hoáº·c filePath!");
        }

        try {
            // KHÃ”NG cáº§n táº£i áº£nh báº±ng axios ná»¯a
            
            // 1. Chuáº©n bá»‹ URI ná»™i bá»™ cho Vision API
            // Vision API cÃ³ thá»ƒ truy cáº­p ná»™i bá»™ Storage qua URI nÃ y
            const imageUri = `gs://${bucketName}/${filePath}`;
            console.log(`ğŸ”„ TrÃ­ch xuáº¥t embedding tá»« URI ná»™i bá»™: ${imageUri}`);

            // 2. Gá»i Vision API Ä‘á»ƒ nháº­n dáº¡ng
            const faceDetection = await detectFaces(imageUri);
            
            // 3. Xá»­ lÃ½ káº¿t quáº£ Vision API
            if (faceDetection.faces.length === 0)
                throw new Error("KhÃ´ng phÃ¡t hiá»‡n khuÃ´n máº·t trong áº£nh!");

            const face = faceDetection.faces[0];
            const embedding = createEmbeddingFromFace(face);

            return {
                success: true,
                embedding,
                confidence: face.detectionConfidence,
                embeddingLength: embedding.length,
            };
        } catch (error) {
            console.error("âŒ Lá»—i khi trÃ­ch xuáº¥t embedding:", error);
            // Quan trá»ng: NÃ©m ra lá»—i Ä‘á»ƒ client Flutter báº¯t Ä‘Æ°á»£c mÃ£ lá»—i
            throw new Error(`Cloud Function Error: ${error.message}`);
        }
    }
);

// =======================================================
// ğŸ”¹ HÃ m test Ä‘Æ¡n giáº£n (HTTP endpoint)
// =======================================================
exports.helloWorld = onRequest(
    { enforceAppCheck: false }, // âš ï¸ Táº¯t App Check Ä‘á»ƒ test nhanh
    (req, res) => {
        console.log("ğŸŒ Hello logs!");
        res.json({
            message: "Hello tá»« Firebase Cloud Functions V2 (AppCheck OFF)!",
            timestamp: new Date().toISOString(),
            nodeVersion: process.version,
            status: "active",
        });
    }
);

// =======================================================
// ğŸ”¹ CÃ¡c hÃ m phá»¥ trá»£ (Helper Functions)
// =======================================================

// ğŸ§  Gá»i Google Vision API Ä‘á»ƒ phÃ¡t hiá»‡n khuÃ´n máº·t
async function detectFaces(imageUri) {
    try {
        // Äáº£m báº£o module Vision Ä‘Ã£ Ä‘Æ°á»£c khai bÃ¡o trong package.json
        const vision = require("@google-cloud/vision"); 
        const client = new vision.ImageAnnotatorClient();
        
        // Gá»i API vá»›i URI ná»™i bá»™ (gs://...)
        const [result] = await client.faceDetection(imageUri); 
        const faces = result.faceAnnotations || [];

        return {
            faces: faces.map((face) => {
                const vertices = face.boundingPoly.vertices || [];
                return {
                    detectionConfidence: face.detectionConfidence || 0,
                    bounds: {
                        x: vertices[0]?.x || 0,
                        y: vertices[0]?.y || 0,
                        width: (vertices[1]?.x || 0) - (vertices[0]?.x || 0),
                        height: (vertices[2]?.y || 0) - (vertices[1]?.y || 0),
                    },
                    landmarks: (face.landmarks || []).map((l) => ({
                        type: l.type || "UNKNOWN",
                        x: l.position?.x || 0,
                        y: l.position?.y || 0,
                        z: l.position?.z || 0,
                    })),
                };
            }),
        };
    } catch (error) {
        console.error("âŒ Vision API error:", error);
        // NÃ©m lá»—i Ä‘á»ƒ Ä‘Æ°á»£c báº¯t á»Ÿ hÃ m gá»i
        throw new Error("Lá»—i khi gá»i Vision API: " + error.message);
    }
}

// ğŸ§© Táº¡o embedding tá»« Ä‘áº·c trÆ°ng khuÃ´n máº·t
function createEmbeddingFromFace(face) {
    const embedding = [];

    embedding.push((face.bounds.x || 0) / 1000);
    embedding.push((face.bounds.y || 0) / 1000);
    embedding.push((face.bounds.width || 0) / 1000);
    embedding.push((face.bounds.height || 0) / 1000);
    embedding.push(face.detectionConfidence || 0);

    const importantLandmarks = ["LEFT_EYE", "RIGHT_EYE", "NOSE_TIP", "MOUTH_LEFT", "MOUTH_RIGHT"];

    importantLandmarks.forEach((type) => {
        const landmark = (face.landmarks || []).find((l) => l.type === type);
        if (landmark) {
            embedding.push((landmark.x || 0) / 1000);
            embedding.push((landmark.y || 0) / 1000);
        } else {
            embedding.push(0, 0);
        }
    });

    console.log(`ğŸ“Š ÄÃ£ táº¡o embedding ${embedding.length} chiá»u`);
    return embedding;
}

// ğŸ”¢ TÃ­nh toÃ¡n Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng Cosine
function calculateCosineSimilarity(vecA, vecB) {
    if (!vecA || !vecB || vecA.length !== vecB.length) return 0;

    let dot = 0,
        normA = 0,
        normB = 0;
    for (let i = 0; i < vecA.length; i++) {
        dot += vecA[i] * vecB[i];
        normA += vecA[i] ** 2;
        normB += vecB[i] ** 2;
    }

    const magnitude = Math.sqrt(normA) * Math.sqrt(normB);
    return magnitude > 0 ? dot / magnitude : 0;
}